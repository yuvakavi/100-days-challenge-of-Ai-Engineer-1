import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train/255.0, x_test/255.0  # Normalize

def build_model(lr):
    model = Sequential([
        Flatten(input_shape=(28, 28)),
        Dense(128, activation='relu'),
        Dense(10, activation='softmax')
    ])
    model.compile(optimizer=Adam(lr),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Train with high learning rate
model_high = build_model(0.1)
history_high = model_high.fit(x_train, y_train, epochs=5, verbose=0)

# Train with low learning rate
model_low = build_model(0.001)
history_low = model_low.fit(x_train, y_train, epochs=5, verbose=0)

# Plot results
plt.plot(history_high.history['loss'], label='LR = 0.1 (High)')
plt.plot(history_low.history['loss'], label='LR = 0.001 (Good)')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Evaluate accuracy
print("High LR Accuracy:", model_high.evaluate(x_test, y_test)[1])
print("Low LR Accuracy:", model_low.evaluate(x_test, y_test)[1])
