# üé® Simple GAN Example (Beginner Friendly)
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LeakyReLU
from tensorflow.keras.optimizers import Adam

# 1Ô∏è‚É£ Load and prepare data
(X_train, _), (_, _) = mnist.load_data()
X_train = X_train.reshape(-1, 784).astype('float32')
X_train = (X_train - 127.5) / 127.5   # scale to [-1,1]

# 2Ô∏è‚É£ Build Generator
generator = Sequential([
    Dense(128, input_dim=100),
    LeakyReLU(0.2),
    Dense(784, activation='tanh')
])

# 3Ô∏è‚É£ Build Discriminator
discriminator = Sequential([
    Dense(128, input_dim=784),
    LeakyReLU(0.2),
    Dense(1, activation='sigmoid')
])

# 4Ô∏è‚É£ Compile both
discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002), metrics=['accuracy'])
discriminator.trainable = False

# 5Ô∏è‚É£ Combine to form GAN
gan = Sequential([generator, discriminator])
gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002))

# 6Ô∏è‚É£ Training Loop (Tiny Example)
for epoch in range(1000):
    # Pick random real images
    idx = np.random.randint(0, X_train.shape[0], 32)
    real_imgs = X_train[idx]

    # Generate fake images
    noise = np.random.normal(0, 1, (32, 100))
    fake_imgs = generator.predict(noise)

    # Train Discriminator
    d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((32, 1)))
    d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((32, 1)))

    # Train Generator
    noise = np.random.normal(0, 1, (32, 100))
    g_loss = gan.train_on_batch(noise, np.ones((32, 1)))

    if epoch % 200 == 0:
        print(f"Epoch {epoch}: D Loss={d_loss_real[0]:.3f}, G Loss={g_loss:.3f}")

# 7Ô∏è‚É£ Generate and show fake images
noise = np.random.normal(0, 1, (1, 100))
generated_image = generator.predict(noise).reshape(28, 28)

plt.imshow(generated_image, cmap='gray')
plt.title("Fake Handwritten Digit by GAN")
plt.show()
