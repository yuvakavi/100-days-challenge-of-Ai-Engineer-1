import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

# ----------------------------
# Teacher Model (Big)
# ----------------------------
class Teacher(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(2, 32)
        self.fc2 = nn.Linear(32, 3)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        return self.fc2(x)

# ----------------------------
# Student Model (Small)
# ----------------------------
class Student(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(2, 8)
        self.fc2 = nn.Linear(8, 3)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        return self.fc2(x)

# Create models
teacher = Teacher()
student = Student()

# Dummy dataset (2 features, 3 classes)
X = torch.tensor([[1.0, 2.0], [2.0, 1.0], [3.0, 4.0], [4.0, 3.0]])
y = torch.tensor([0, 1, 2, 1])

# Optimizer
optimizer = optim.Adam(student.parameters(), lr=0.01)

# Temperature and loss weight
T = 3.0
alpha = 0.7

# Pretend teacher is already trained
teacher.eval()

# ----------------------------
# Knowledge Distillation Training
# ----------------------------
for epoch in range(200):
    student.train()
    optimizer.zero_grad()

    # Teacher predictions (soft targets)
    with torch.no_grad():
        teacher_logits = teacher(X)
        soft_targets = F.softmax(teacher_logits / T, dim=1)

    # Student predictions
    student_logits = student(X)

    # Distillation loss (soft labels)
    distill_loss = F.kl_div(
        F.log_softmax(student_logits / T, dim=1),
        soft_targets,
        reduction="batchmean"
    ) * (T * T)

    # Normal classification loss (hard labels)
    hard_loss = F.cross_entropy(student_logits, y)

    # Combined loss
    loss = alpha * distill_loss + (1 - alpha) * hard_loss

    loss.backward()
    optimizer.step()

# ----------------------------
# Test Student
# ----------------------------
student.eval()
test_input = torch.tensor([[3.0, 2.0]])
prediction = student(test_input)
predicted_class = prediction.argmax(dim=1)

print("Student Prediction:", predicted_class.item())
